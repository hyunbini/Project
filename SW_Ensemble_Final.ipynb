{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1A0WDSDWqDWmRz7+KbKNd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyunbini/Project/blob/main/SW_Ensemble_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Library and Preparation"
      ],
      "metadata": {
        "id": "tZRklWhfyFwP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6-xjpEFSCr4"
      },
      "outputs": [],
      "source": [
        "pip install scikit-learn xgboost catboost pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing the Colab Environment: Installing Java + Konlpy + mecab-ko\n",
        "!apt-get -qq update\n",
        "!apt-get -y -qq install openjdk-11-jdk curl git\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] += \":\" + os.path.join(os.environ[\"JAVA_HOME\"], \"bin\")\n",
        "\n",
        "!pip -q install JPype1==1.5.0 konlpy==0.6.0"
      ],
      "metadata": {
        "id": "7UElJiyOUehv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete an existing folde\n",
        "!rm -rf Mecab-ko-for-Google-Colab\n",
        "\n",
        "# 2. Cloned again the Repository\n",
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git"
      ],
      "metadata": {
        "id": "qn50VAv3IOTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd Mecab-ko-for-Google-Colab/"
      ],
      "metadata": {
        "id": "Gdmxn9oVIO2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the installation script\n",
        "!bash install_mecab-ko_on_colab_light_220429.sh"
      ],
      "metadata": {
        "id": "SYly6kFKIQMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the hanspell to use preprocessing\n",
        "!pip install git+https://github.com/ssut/py-hanspell.git"
      ],
      "metadata": {
        "id": "rHUimFrqWuJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Library"
      ],
      "metadata": {
        "id": "jkDDbPSvyN7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
        "from konlpy.tag import Mecab\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "from hanspell import spell_checker\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "gamddA_iUAk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mecab = Mecab()"
      ],
      "metadata": {
        "id": "0DF83H8jYkgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing Function"
      ],
      "metadata": {
        "id": "9TcWRtfHyeOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove special characters\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'<[^>]+>', ' ', text)\n",
        "    text = re.sub(r'http\\S+|www\\S+', ' ', text)\n",
        "    text = re.sub(r'\\S+@\\S+', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "# Count the typo\n",
        "def count_typos(text):\n",
        "    try:\n",
        "        result = spell_checker.check(text)\n",
        "        return result.errors\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "# Check the presence of emoticons\n",
        "def has_emoji_or_special(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"\n",
        "        u\"\\U0001F300-\\U0001F5FF\"\n",
        "        u\"\\U0001F680-\\U0001F6FF\"\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"\n",
        "        \"]+\", flags=re.UNICODE)\n",
        "    special_pattern = re.compile(r'[^\\w\\sㄱ-ㅎ가-힣]')\n",
        "    return bool(emoji_pattern.search(text)) or bool(special_pattern.search(text))\n",
        "\n",
        "# Frequency of adverbs\n",
        "def adverb_ratio(text):\n",
        "    tokens = mecab.pos(text)\n",
        "    return len([w for w, pos in tokens if pos == 'MAG']) / len(tokens) if tokens else 0\n",
        "# Check zipf's law score\n",
        "def zipf_score(text):\n",
        "    words = [w for w in mecab.morphs(text) if len(w) > 1]\n",
        "    freqs = Counter(words)\n",
        "    ranks = np.arange(1, len(freqs)+1)\n",
        "    freqs_sorted = np.array(sorted(freqs.values(), reverse=True))\n",
        "    if len(freqs_sorted) < 2:\n",
        "        return 0\n",
        "    return np.corrcoef(np.log(ranks), np.log(freqs_sorted))[0, 1]"
      ],
      "metadata": {
        "id": "79ob-QQ5WuoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_dataframe(df, text_col='full_text'):\n",
        "    tqdm.pandas()\n",
        "    df['text_clean'] = df[text_col].progress_apply(clean_text)\n",
        "    df['typo_count'] = df['text_clean'].progress_apply(count_typos)\n",
        "    df['has_emoji_special'] = df['text_clean'].progress_apply(has_emoji_or_special)\n",
        "    df['adv_ratio'] = df['text_clean'].progress_apply(adverb_ratio)\n",
        "    df['zipf_corr'] = df['text_clean'].progress_apply(zipf_score)\n",
        "    return df"
      ],
      "metadata": {
        "id": "LVxUtUEfYo4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mecab_tokenizer(text):\n",
        "        return mecab.morphs(text)"
      ],
      "metadata": {
        "id": "56sh3qJGxA21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function defined by mecab morpheme analyzer-based tokenizer\n",
        "def tokenize(df, text_col):\n",
        "  vectorizer = TfidfVectorizer(\n",
        "      tokenizer=mecab_tokenizer,\n",
        "      ngram_range=(1, 2),\n",
        "      max_features=10000\n",
        "  )\n",
        "  vector_data = vectorizer.fit_transform(df[text_col])\n",
        "  return vector_data"
      ],
      "metadata": {
        "id": "Ep2ei8ipYsHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data I/O Function"
      ],
      "metadata": {
        "id": "qnHKjUUVy43Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "  # Load the data\n",
        "  train_df = pd.read_csv('/content/drive/MyDrive/Data/train.csv', encoding='utf-8-sig')\n",
        "  train_df = preprocess_dataframe(train_df, text_col='full_text')\n",
        "\n",
        "  # Encoding the label\n",
        "  label_encoder = LabelEncoder()\n",
        "  y = label_encoder.fit_transform(train_df['generated'])\n",
        "  X = tokenize(train_df,'full_text')\n",
        "\n",
        "  # Split the train / test dataset\n",
        "  X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "  return X_train, y_train, X_val, y_val, label_encoder"
      ],
      "metadata": {
        "id": "AvNNJC5HYsq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modeling Function"
      ],
      "metadata": {
        "id": "TmkjxCDMzBg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_model(X_train, y_train, X_val, y_val):\n",
        "# Learning individual models\n",
        "  xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "  xgb_model.fit(X_train, y_train)\n",
        "\n",
        "  cat_model = CatBoostClassifier(verbose=0)\n",
        "  cat_model.fit(X_train, y_train)\n",
        "\n",
        "  rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "  rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Soft Voting Forecast (validation train Set)\n",
        "  xgb_probs = xgb_model.predict_proba(X_val)\n",
        "  cat_probs = cat_model.predict_proba(X_val)\n",
        "  rf_probs = rf_model.predict_proba(X_val)\n",
        "  avg_probs = (xgb_probs + cat_probs + rf_probs) / 3\n",
        "  ensemble_preds = np.argmax(avg_probs, axis=1)\n",
        "\n",
        "# Print Evaluation Score\n",
        "  print(classification_report(y_val, ensemble_preds))\n",
        "  print(\"Accuracy:\", accuracy_score(y_val, ensemble_preds))\n",
        "  print(\"ROC-AUC:\", roc_auc_score(y_val, avg_probs[:, 1]))\n",
        "  return xgb_model, cat_model, rf_model"
      ],
      "metadata": {
        "id": "K-QDOs8Dac6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction of results for test sets\n",
        "def test(xgb_model,cat_model,rf_model,label_encoder):\n",
        "  test_df = pd.read_csv('/content/drive/MyDrive/Data/test.csv', encoding='utf-8-sig')\n",
        "  X_test_final = tokenize(test_df,'paragraph_text')\n",
        "\n",
        "  xgb_test_probs = xgb_model.predict_proba(X_test_final)\n",
        "  cat_test_probs = cat_model.predict_proba(X_test_final)\n",
        "  rf_test_probs = rf_model.predict_proba(X_test_final)\n",
        "\n",
        "  avg_test_probs = (xgb_test_probs + cat_test_probs + rf_test_probs) / 3\n",
        "  test_preds = np.argmax(avg_test_probs, axis=1)\n",
        "  test_labels = label_encoder.inverse_transform(test_preds)\n",
        "\n",
        "  # Save the results to a submission file\n",
        "  submission = pd.read_csv('/content/drive/MyDrive/Data/submission.csv')\n",
        "  submission['generated'] = test_labels\n",
        "  submission.to_csv('/content/drive/MyDrive/Data/submission.csv', index=False)\n",
        "\n",
        "  print(\"Finish\")"
      ],
      "metadata": {
        "id": "aJumTguqYzyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main Function"
      ],
      "metadata": {
        "id": "xiFiGLNvzFTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  train_x,train_y,test_x,test_y,label = load_data()\n",
        "  model_xgb,model_cat,model_rf = train_and_evaluate_model(train_x,train_y,test_x,test_y)\n",
        "  test(model_xgb,model_rf,rf_model,label)"
      ],
      "metadata": {
        "id": "UTE1bVd0uZsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if _name_ == \"_main_\":\n",
        "  main()"
      ],
      "metadata": {
        "id": "zY9J5-_XwiC9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}